{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = \"./data/train.csv\"\n",
    "kaggle_train_df = pd.read_csv(path)\n",
    "path = \"./data/test.csv\"\n",
    "kaggle_test_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Some Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'FullBath', 'HalfBath',\n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', \n",
    "    'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
    "    'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold',\n",
    "    'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    \"CentralAir\", \"ExterQual\", \"LandSlope\", \"Condition2\", \"ExterCond\",\n",
    "    \"LandContour\", \"HouseStyle\", \"BldgType\", \"RoofStyle\", \"Foundation\",\n",
    "    \"GrLivArea\", \"RoofMatl\", \"Id\", \"Condition1\"\n",
    "]\n",
    "\n",
    "col_selected = {key:[key] for key in num_cols + cat_cols}\n",
    "col_y = \"SalePrice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Where the Files Are to Be Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "dbhost = cwd + \"/local_documents\"\n",
    "home_path = cwd + \"/local_storage\"\n",
    "\n",
    "project = \"ml_forest_dev_sample\"\n",
    "\n",
    "db = {\"host\": dbhost, \"project\": project}\n",
    "filepaths = [{\"home\": home_path, \"project\": project}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Sklearn Classes to Be Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Up the Sklearn Classes for Usage in `ml_forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ml_forest.core.elements.ftrans_base import SklearnRegressor\n",
    "from ml_forest.core.elements.ftrans_base import SklearnUnsupervised\n",
    "\n",
    "class GenerateStandardScalor(SklearnUnsupervised):\n",
    "    def __init__(self):\n",
    "        super(GenerateStandardScalor, self).__init__(model_type=StandardScaler)\n",
    "        self.__essentials = {}\n",
    "    \n",
    "class GenerateOneHotEncode(SklearnUnsupervised):\n",
    "    def __init__(self):\n",
    "        super(GenerateOneHotEncode, self).__init__(model_type=OneHotEncoder, sparse=False)\n",
    "        self.__essentials = {}\n",
    "\n",
    "class GenerateLasso(SklearnRegressor):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GenerateLasso, self).__init__(model_type=Lasso, **kwargs)\n",
    "        self.__essentials = {}\n",
    "        \n",
    "class GenerateSVR(SklearnRegressor):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(GenerateSVR, self).__init__(model_type=SVR, **kwargs)\n",
    "        self.__essentials = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ml_forest.pipeline.pipe_init import PipeInit\n",
    "\n",
    "train_init = PipeInit(\n",
    "    data=kaggle_train_df, col_y=col_y, col_selected=col_selected,\n",
    "    lst_layers=[2,3],\n",
    "    db=db, filepaths = filepaths\n",
    ")\n",
    "\n",
    "core_docs = train_init.core\n",
    "init_fnodes = train_init.init_fnodes\n",
    "init_lnode = train_init.init_lnode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ml_forest.pipeline.nodes.stacking_node import FNode, LNode\n",
    "\n",
    "# Nodes that one-hot encode categorical features\n",
    "dummied_fnodes = []\n",
    "for key in cat_cols:\n",
    "    cat = init_fnodes[key]\n",
    "    one_hot_encoder = GenerateOneHotEncode()\n",
    "    \n",
    "    dummied_fnodes.append(\n",
    "        FNode(core_docs, [cat], one_hot_encoder)\n",
    "    )\n",
    "\n",
    "# nodes that normalize numerical features\n",
    "num_fnodes = []\n",
    "for key in num_cols:\n",
    "    num = init_fnodes[key]\n",
    "    standardizer = GenerateStandardScalor()\n",
    "    \n",
    "    num_fnodes.append(\n",
    "        FNode(core_docs, [num], standardizer)\n",
    "    )\n",
    "\n",
    "# Node that generates new features from one-hot encoded cetegorical features by lasso\n",
    "lasso = GenerateLasso()\n",
    "lasso_node = FNode(core_docs, dummied_fnodes, lasso, init_lnode)\n",
    "\n",
    "# Node that makes final output from normalized numerical features and one-hot encoded \n",
    "# categorical features by SVR\n",
    "svr = GenerateSVR()\n",
    "svr_node = FNode(core_docs, num_fnodes+[lasso_node], svr, init_lnode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the Nodes to Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ml_forest.pipeline.links.knitor import Knitor\n",
    "\n",
    "kn = Knitor()\n",
    "svr_feature, svr = kn.f_knit(svr_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso = GenerateLasso(alpha=0.01)\n",
    "lasso_node = FNode(core_docs, dummied_fnodes, lasso, init_lnode)\n",
    "\n",
    "svr = GenerateSVR(degree=1, C=10)\n",
    "svr_node = FNode(core_docs, num_fnodes+[lasso_node], svr, init_lnode)\n",
    "\n",
    "kn = Knitor()\n",
    "svr_feature, svr = kn.f_knit(svr_node)\n",
    "svr_feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr = GenerateSVR(degree=1, C=100)\n",
    "svr_node = FNode(core_docs, num_fnodes+[lasso_node], svr, init_lnode)\n",
    "\n",
    "kn = Knitor()\n",
    "svr_feature, svr = kn.f_knit(svr_node)\n",
    "svr_feature.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ml_forest.core.utils.docs_init import root_database\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "f_collection = root_database[project][\"Feature\"]\n",
    "ft_collection = root_database[project][\"FTransform\"]\n",
    "\n",
    "def get_content(doc, core):\n",
    "    if \"f_transform\" in doc[\"essentials\"] and doc[\"essentials\"][\"f_transform\"]:\n",
    "        ft_id = doc[\"essentials\"][\"f_transform\"]\n",
    "        found = [d for d in ft_collection if d[\"_id\"]==ft_id]\n",
    "        ft_doc = found[0]\n",
    "        \n",
    "        ft_name = str(ft_doc[\"essentials\"][\"type\"]).split(\".\")[-1]\n",
    "        ft_name = ''.join(x for x in ft_name if x.isalpha())\n",
    "        \n",
    "        return ft_name\n",
    "    else:\n",
    "        f_id = doc[\"_id\"]\n",
    "        dict_f = core.init_features.copy()\n",
    " \n",
    "        tmp = [key for key in dict_f if dict_f[key] == f_id]\n",
    "        if tmp:\n",
    "            f_name = tmp[0]\n",
    "        else:\n",
    "            f_name = None\n",
    "        \n",
    "        return f_name\n",
    "\n",
    "def collection_single_f(f_id, core):    \n",
    "    found = [d for d in f_collection if d[\"_id\"]==f_id]\n",
    "    if len(found)> 1:\n",
    "        raise ValueError(\"There are more than one document with the objectid you passed\")\n",
    "\n",
    "    f_doc = found[0]\n",
    "        \n",
    "    content = get_content(f_doc, core)\n",
    "    if f_doc[\"essentials\"][\"lst_fed\"]:\n",
    "        child_f_id = set(f_doc[\"essentials\"][\"lst_fed\"])\n",
    "    else:\n",
    "        child_f_id = set()\n",
    "    \n",
    "    return {\"_id\":f_id, \"child\": child_f_id, \"content\":content}\n",
    "\n",
    "\n",
    "def collect4fid(f_id, core):\n",
    "    to_be_searched = {f_id}\n",
    "    \n",
    "    i = 0\n",
    "    result = {}\n",
    "    while to_be_searched:\n",
    "        result_layer = []\n",
    "        tmp = set()\n",
    "        for id_2b_searched in to_be_searched:\n",
    "            doc = collection_single_f(id_2b_searched, core)\n",
    "            result_layer.append(doc)\n",
    "            tmp = tmp.union(set(doc[\"child\"]))\n",
    "        result[i] = result_layer\n",
    "        to_be_searched = tmp\n",
    "        i+=1\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_id =  svr_feature.obj_id\n",
    "docs = collect4fid(f_id, core_docs)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
